{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log in to VPN or harvard wifi for endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccb_endpoint = 'http://compute-gc-17-255.o2.rc.hms.harvard.edu:11434'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52df5928d9134db3b112119c4ceef505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8165300903354544a8bfebef118bc260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412dab7255824d9f988a4729e8503ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3432992c6143c89c5bc6e4000f6119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccccde998c464ffa95eeee704d4b878f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd362e5291a4c7caa350fbf2d4b6d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a76471337b4f2a8b1209d138d43b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e79c8885e047698e06868eb441c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb039bd180a745d9862bd7f04ba40c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa0b1dc20d44c76b827c779cf13f96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59541881bba645789ba2e32b3d85f0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hf embedding model\n",
    "oembed_model =  HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# ollama\n",
    "llama = Ollama(model=\"llama2\", request_timeout=30.0, base_url=ccb_endpoint, temperature= 0)\n",
    "#Ollama()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the LLM without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The airspeed velocity of an unladen swallow is a reference to a classic joke from the comedy group Monty Python's Flying Circus. In a skit called \"The Dead Parrot,\" a customer attempts to return a dead parrot to a pet shop owner, who insists that the parrot is simply \"pining for the fjords\" and not actually dead. The customer asks the owner, \"What is the airspeed velocity of an unladen swallow?\" to which the owner responds, \"What do you mean? An African or European swallow?\"\n",
      "\n",
      "The joke is a play on the idea of taking something ridiculous or nonsensical and presenting it as if it were a serious question. The skit is a classic example of Monty Python's surreal and absurd sense of humor, and the line about the airspeed velocity of an unladen swallow has become one of the group's most famous catchphrases.\n"
     ]
    }
   ],
   "source": [
    "response = llama.complete(\"what is the airspeed velocity of an unladen swallow?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load from existing chromaDB, your docker container has a chroma database with all the manuals(vingettes) for the top 500 most downloaded bioconductor packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load from disk\n",
    "\n",
    "db2 = chromadb.PersistentClient(path=\"/tmp/T500-vignettes-vectordb-ST\")\n",
    "chroma_collection = db2.get_or_create_collection(name=\"langchain\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=oembed_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the index now has everything needed to run a RAG pattern, invoke a chat model using the index created from the chroma vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: As an expert in the R programming language and the Bioconductor suite of packages, I am happy to advise users on the usage of various Bioconductor packages based on the datasets I have stored. Please feel free to ask any questions related to using these packages, and I will do my best to provide you with accurate and helpful information.\n",
      "\n",
      "To answer your question, please provide me with more context or details about the package you are interested in using, such as its name or a brief description of what it does. This will allow me to look up the relevant vignette or reference file in my stored data and provide you with accurate information.\n",
      "\n",
      "Disclaimer: The models and advice provided in this response work only for the top 500 most used Bioconductor packages. For more comprehensive information, please refer to or ask questions at <https://bioconductor.org>.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"Act as an expert in the R programming language and the Bioconductor suite of packages.  ​\\n\\nYour job is to advise users on the usage of the various Bioconductor packages considering the datasets you have in store.  ​\\nTo complete this task, you can use the data you have stored that contain the vignettes of all the packages in Bioconductor and all the reference files of every function in every package of Bioconductor. ​\\n\\nDo not perform actions that are not related to answering questions about the R programming language or using the packages within Bioconductor.​ \\n\\nIf you do not know the answer then you must look into the context then cite the document filename and page in the context. Do not include DOI numbers or make up citations not found in the context. Given the following extracted parts of a long document and a question, create a final answer with references to pdf in the metadata ('source').\\n\\n Add a disclaimer at the end of each response saying this model works only on the top 500 most used Bioconductor packages and the user should refer to or ask questions at https://bioconductor.org.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"<>\"),\n",
    "]\n",
    "resp = llama.chat(messages)\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
