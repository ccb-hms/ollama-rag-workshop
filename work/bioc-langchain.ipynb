{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f2bfe8-eab6-495f-ac27-5c436800ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "#from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328ef69",
   "metadata": {},
   "source": [
    "# log in to VPN or harvard wifi for endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d1e929-1b05-42de-abcc-d18bc6e7545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the LLM \n",
    "ccb_endpoint = 'http://compute-gc-17-255.o2.rc.hms.harvard.edu:11434'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3089973f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b85438da8e4398b88d8d6025f5e2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b48d620af4a4895961bdb08564dc305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79ff443ec0d40c893d28779de518731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b19167ae634513905b6b7c8d030164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57eed87f58c48fc95186c13fa9e0dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624a51f085e342f18ac8971cc5e73950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de76ac37f0b41dc9cdfb1bbcf38d9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdb37c4972741f589134ed3423ab178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d722b13a644774a2a5888c96a0c4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ee376495d64871835e9fcafed7a465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87324c80d11a499fa1d6ac1c25f53216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the model and temperature\n",
    "llm = Ollama(base_url= ccb_endpoint, model=\"llama2\", temperature=0)\n",
    "#create the embedding model\n",
    "oembed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c2c21",
   "metadata": {},
   "source": [
    "### Now we can invoke a generated response from the model. Test it out by filling in the quotes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f2598f-26cb-4dad-a5eb-96879dd5ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SummarizedExperiment is a tool in the Google Cloud Platform that allows you to summarize and analyze large datasets. It is designed to help data scientists and analysts quickly and easily identify the most important insights from complex datasets, without having to spend hours or days manually analyzing the data.\n",
      "\n",
      "SummarizedExperiment uses machine learning algorithms to automatically generate a summary of the dataset, including key findings, trends, and patterns. This summary is presented in an easy-to-understand format, such as a report or dashboard, that can be shared with stakeholders.\n",
      "\n",
      "Some of the key features of SummarizedExperiment include:\n",
      "\n",
      "1. Automated summarization: SummarizedExperiment uses machine learning algorithms to automatically generate a summary of the dataset, without requiring manual analysis.\n",
      "2. Customizable summaries: Users can customize the summary to focus on specific aspects of the data, such as trends, patterns, or insights.\n",
      "3. Interactive visualizations: SummarizedExperiment provides interactive visualizations that allow users to explore the data in more detail, and gain a deeper understanding of the insights identified by the algorithm.\n",
      "4. Collaboration tools: SummarizedExperiment allows multiple users to collaborate on summaries, making it easier to share insights and work together on projects.\n",
      "5. Integration with other Google Cloud tools: SummarizedExperiment integrates with other Google Cloud tools, such as BigQuery and Data Studio, allowing users to easily incorporate the summaries into their existing workflows.\n",
      "\n",
      "Overall, SummarizedExperiment is a powerful tool for data scientists and analysts who need to quickly and easily identify important insights from large datasets. It can help organizations make more informed decisions by providing a clear and concise summary of the data, without requiring manual analysis.\n"
     ]
    }
   ],
   "source": [
    "chat_model_response = llm.invoke(\"what is summarizedExperiment\")\n",
    "print(chat_model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f36e73",
   "metadata": {},
   "source": [
    "### load from existing chromaDB, your docker container has a chroma database with all the manuals(vingettes) for the top 500 most downloaded bioconductor packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3623c1-1076-4881-b8ca-36ae58db8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from persist \n",
    "T500bioc_db = Chroma(persist_directory=\"/tmp/T500-vignettes-vectordb-ST/\", embedding_function=oembed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a76612",
   "metadata": {},
   "source": [
    "#### We can now use the embedding model and vector database a retriever to guide the generative AI (llama2). Below we define a system prompt and the RAG pipeline as a \"chain\" written in LangChain Expression Language(LCEL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05520439-c28e-4750-8fa2-97e46e2695bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = T500bioc_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Act as an expert in the R programming language and the Bioconductor suite of packages.  ​\\n\\nYour job is to advise users on the usage of the various Bioconductor packages considering the datasets you have in store.  ​\\nTo complete this task, you can use the data you have stored that contain the vignettes of all the packages in Bioconductor and all the reference files of every function in every package of Bioconductor. ​\\n\\nDo not perform actions that are not related to answering questions about the R programming language or using the packages within Bioconductor.​ \\n\\nIf you do not know the answer then you must look into the context then cite the document filename and page in the context. Do not include DOI numbers or make up citations not found in the context. \n",
    "Given the following extracted parts of a long document and a question, create a final answer with references to pdf in the metadata ('source').\\n\\n Add a disclaimer at the end of each response saying this model works only on the top 500 most used Bioconductor packages and the user should refer to or ask questions at https://bioconductor.org.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "FINAL ANSWER: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef172290",
   "metadata": {},
   "source": [
    "### Test the LLM without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae4e526-e79e-4bc5-86f8-e5a9f0019f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The `SummarizedExperiment` package provides a variety of classes for summarizing and visualizing experimental data. Here are some of the main classes provided by the package:\n",
      "\n",
      "1. `Summary`: This is the base class for all summary objects in the package. It provides methods for calculating summary statistics, such as means, standard deviations, and counts, as well as methods for visualizing the data.\n",
      "2. `Experiment`: This class represents an entire experiment, including all of the observations and variables. It provides methods for calculating summary statistics for the entire experiment, as well as methods for visualizing the data.\n",
      "3. `Observation`: This class represents a single observation in an experiment. It provides methods for calculating summary statistics for a single observation, as well as methods for visualizing the data.\n",
      "4. `Variable`: This class represents a variable in an experiment. It provides methods for calculating summary statistics for a single variable, as well as methods for visualizing the data.\n",
      "5. `SummaryTable`: This class provides a convenient way to display summary statistics for multiple variables in a table format.\n",
      "6. `Plot`: This class provides a convenient way to create various types of plots, such as bar plots, line plots, and scatter plots, to visualize experimental data.\n",
      "7. `Heatmap`: This class provides a convenient way to create heatmaps to visualize high-dimensional data.\n",
      "8. `PCA`: This class provides a convenient way to perform principal component analysis (PCA) on experimental data.\n",
      "9. `tSNE`: This class provides a convenient way to perform t-distributed Stochastic Neighbor Embedding (t-SNE) on experimental data.\n",
      "10. `Visualization`: This class provides a convenient way to create various types of visualizations, such as scatter plots, bar plots, and heatmaps, to visualize experimental data.\n",
      "\n",
      "These are some of the main classes provided by the `SummarizedExperiment` package. There may be other classes available depending on the version of the package you are using.\n"
     ]
    }
   ],
   "source": [
    "#test without rag\n",
    "chat_model_response = llm.invoke(\"How many classes are there in the SummarizedExperiment package?\")\n",
    "print(chat_model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98a84b",
   "metadata": {},
   "source": [
    "### Now invoke the LLM with the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0204936f-f4e0-4b99-b196-ac98e73611bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the documentation provided, the SummarizedExperiment package contains two classes: `SummarizedExperiment` and `RangedSummarizedExperiment`. The `SummarizedExperiment` class is a matrix-like container that represents features of interest (such as genes, transcripts, exons, etc.) and samples. It can contain one or more assays, each represented by a matrix-like object of numeric or other mode.\n",
      "\n",
      "The `RangedSummarizedExperiment` class is an extension of the `SummarizedExperiment` class that allows for the representation of ranges of values for the features of interest.\n",
      "\n",
      "Therefore, there are two classes in the SummarizedExperiment package: `SummarizedExperiment` and `RangedSummarizedExperiment`."
     ]
    }
   ],
   "source": [
    "# Run with Retrival augment\n",
    "for chunk in rag_chain.stream(\"How many classes are there in the SummarizedExperiment package?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534625cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without streaming loop\n",
    "query = \"How many classes are there in the SummarizedExperiment package?\"\n",
    "response = rag_chain.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aeb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#programmatic access to csv\n",
    "import polars as pl\n",
    "df = pl.read_csv('bioc_qa.csv')\n",
    "questions = df['Question'].to_list()\n",
    "answers_rag = []\n",
    "\n",
    "for query in questions:\n",
    "    result = rag_chain.invoke(query)\n",
    "    answers_rag.append(result)\n",
    "\n",
    "answers_rag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f407a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plain_template = \"\"\"\n",
    "Act as an expert in the R programming language and the Bioconductor suite of packages. \n",
    "Your job is to advise users on the usage of the various Bioconductor packages.  \n",
    "Do not perform actions that are not related to answering questions about the R programming language or using the packages within Bioconductor.​ \n",
    "If you do not know the answer ask the user to refer to https://bioconductor.org. \n",
    "Add a disclaimer at the end of each response saying this model works only on the top 500 most used Bioconductor packages.\n",
    "\n",
    "QUESTION: {question}\n",
    "FINAL ANSWER: \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(plain_template)\n",
    "\n",
    "non_rag_chain = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925dbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in non_rag_chain.stream(\"What is SummarizedExperiment?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
